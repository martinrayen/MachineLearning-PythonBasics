{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#======= Import the neccessary modules ===================================\n",
    "import os\n",
    "import json\n",
    "import sys\n",
    "import uuid\n",
    "import linecache\n",
    "from datetime import datetime\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "#=========================================================================\n",
    "# Class definition\n",
    "class modMLModelingPipeline:\n",
    "    # Instantiate all variables and methods required for the class.\n",
    "    def __init__(self,ClientID,ClientName,Source,Output,\n",
    "                 TrainedModel,ExecutionLog,ExecutionLogFileName,Archive,\n",
    "                 dfX,dfY,total_rowCount,IsTimeBasedSplitting,Training_split_ratio,\n",
    "                 Crossvalidation_split_ratio, Test_split_ratio\n",
    "                ):\n",
    "        #====== Set all the App config parameters from the json, input and output data ======\n",
    "        self.ClientID                    = ClientID\n",
    "        self.ClientName                  = ClientName\n",
    "        self.Source                      = Source\n",
    "        self.Output                      = Output\n",
    "        self.TrainedModel                = TrainedModel\n",
    "        self.ExecutionLog                = ExecutionLog\n",
    "        self.ExecutionLogFileName        = ExecutionLogFileName\n",
    "        self.Archive                     = Archive\n",
    "        self.dfX                         = dfX\n",
    "        self.dfY                         = dfY\n",
    "        self.total_rowCount              = total_rowCount\n",
    "        self.IsTimeBasedSplitting        = IsTimeBasedSplitting\n",
    "        self.Training_split_ratio        = Training_split_ratio\n",
    "        self.Crossvalidation_split_ratio = Crossvalidation_split_ratio\n",
    "        self.Test_split_ratio            = Test_split_ratio\n",
    "        #====================================================================================\n",
    "\n",
    "    # Split the input and output variables based on specified splitting ratios.\n",
    "    def split_data(self):\n",
    "        #====== Variables to hold the split data ====================\n",
    "        global X_train\n",
    "        global X_cv\n",
    "        global X_test\n",
    "        global Y_train\n",
    "        global Y_cv\n",
    "        global Y_test\n",
    "        #===========================================================\n",
    "        # Check, if timebased splitting is required.\n",
    "        if self.IsTimeBasedSplitting == 1:\n",
    "            #Do time based splitting.\n",
    "            # Split the training set.\n",
    "            trainingUBound = round(self.Training_split_ratio * self.total_rowCount)\n",
    "            X_train = self.dfX[0:trainingUBound]\n",
    "            Y_train = self.dfY[0:trainingUBound]\n",
    "            # Split the cross-validation set.\n",
    "            crossvalidationLBound = trainingUBound\n",
    "            crossvalidationUBound = crossvalidationLBound + round(self.Crossvalidation_split_ratio * self.total_rowCount)\n",
    "            X_cv = self.dfX[crossvalidationLBound:crossvalidationUBound]\n",
    "            Y_cv = self.dfY[crossvalidationLBound:crossvalidationUBound]\n",
    "            # Split the test set.\n",
    "            testLBound = crossvalidationUBound\n",
    "            testUBound = testLBound + round(self.Test_split_ratio * self.total_rowCount)\n",
    "            X_test = self.dfX[testLBound:testUBound]\n",
    "            Y_test = self.dfY[testLBound:testUBound]\n",
    "        else:\n",
    "            # Do random splitting.\n",
    "            cv_size   = (2 * self.Crossvalidation_split_ratio) # 0.4\n",
    "            test_size = Test_split_ratio                       # 0.2\n",
    "            X_train ,X_cv = train_test_split(self.dfX,test_size=cv_size) \n",
    "            Y_train ,Y_cv = train_test_split(self.dfY,test_size=cv_size) \n",
    "            X_cv ,X_test  = train_test_split(X_cv,test_size=test_size) \n",
    "            Y_cv ,Y_test  = train_test_split(Y_cv,test_size=test_size)\n",
    "\n",
    "        # Return the split data.\n",
    "        return X_train,X_cv,X_test,Y_train,Y_cv,Y_test\n",
    "        \n",
    "    # Standardize or Normalize the data.\n",
    "    def standardize_data(self,IsNormalize=0):\n",
    "        global X_train_stdzd\n",
    "        global X_cv_stdzd\n",
    "        global X_test_stdzd\n",
    "        global Y_train_ravel\n",
    "        global Y_cv_ravel\n",
    "        global Y_test_ravel\n",
    "        \n",
    "        # Check, if data is to be normalized/standardized.\n",
    "        if IsNormalize == 1:\n",
    "            # Instantiate the normalizer\n",
    "            normalizer = Normalizer()\n",
    "        else:\n",
    "            # Instantiate the standardizer\n",
    "            normalizer = StandardScaler()\n",
    "            \n",
    "        #Standardize the data.\n",
    "        X_train_stdzd = normalizer.fit_transform(X_train)\n",
    "        X_cv_stdzd    = normalizer.transform(X_cv)\n",
    "        X_test_stdzd  = normalizer.transform(X_test)\n",
    "        \n",
    "        #Flatten the Y into 1D array.\n",
    "        Y_train_ravel = np.ravel(Y_train, order = 'C') \n",
    "        Y_cv_ravel    = np.ravel(Y_cv, order = 'C') \n",
    "        Y_test_ravel  = np.ravel(Y_test, order = 'C') \n",
    "        \n",
    "        # Return the standardized data.\n",
    "        return X_train_stdzd,X_cv_stdzd,X_test_stdzd,Y_train_ravel,Y_cv_ravel,Y_test_ravel\n",
    "        \n",
    "\n",
    "    # Method to return the non-calibrated model after training.\n",
    "    def GetTrainedModel(self,optimalHyperparameter):\n",
    "        # instantiate the Logistic Regression model with the optimal lambda.\n",
    "        global lr_optimal\n",
    "        lr_optimal = LogisticRegression(penalty='l2',              # use L2 regularizer.\n",
    "                                        C=(optimalHyperparameter), # use Inverse of Lambda.\n",
    "                                        class_weight='balanced',   # uses the values of y to automatically adjust \n",
    "                                                                   # weights in the input \n",
    "                                                                   # data, since we have class imbalance.\n",
    "                                        solver='liblinear')        # solver = 'liblinear' because of low dimension and \n",
    "                                                                   # L2 regularizer.\n",
    "\n",
    "        lr_optimal.fit(X_train_stdzd, Y_train_ravel)     # fitting the Logistic Regression model.\n",
    "        return lr_optimal\n",
    "        \n",
    "    # Method to return the calibrated model after training.\n",
    "    def GetCalibratedModel(self):\n",
    "        ### Use CalibratedClassifierCV\n",
    "        # Instantiate the CalibratedClassifierCV model.\n",
    "        global calibratedCCV\n",
    "        calibratedCCV = CalibratedClassifierCV(lr_optimal,       # Logistic Regression model.\n",
    "                                               method='sigmoid', # sigmoid function.\n",
    "                                               cv=5)             # crossvalidation #'s.\n",
    "    \n",
    "        calibratedCCV.fit(X_train_stdzd, Y_train_ravel)          # fit the model on the training set.\n",
    "        return calibratedCCV\n",
    "\n",
    "    # Method to get predictions.\n",
    "    def GetPredictions(self):\n",
    "        global Y_pred_test\n",
    "        Y_pred_test = lr_optimal.predict(X_test_stdzd)   # predict,response from the Logistic Regression model.\n",
    "        return X_test_stdzd, Y_pred_test\n",
    "    \n",
    "    # Method to get calibrated predictons.\n",
    "    def GetCalibratedPredictions(self):\n",
    "        global Y_pred_calib\n",
    "        Y_pred_calib = calibratedCCV.predict_proba(X_test_stdzd)[:, 1]   # predict class probabilities on the testset.\n",
    "        return X_test_stdzd, Y_pred_calib\n",
    "    \n",
    "    # Method to get the classifier metrics.\n",
    "    def GetModelConfusionMatrix(self):\n",
    "        # Plot the confusion matrix for the trained model.\n",
    "        conf_mat = confusion_matrix(Y_test, Y_pred_test)\n",
    "        fig, ax = plt.subplots(figsize=(5,5))\n",
    "        sns.heatmap(conf_mat, annot=True, fmt='d'\n",
    "                    ,xticklabels=['Not Selected','Selected'], yticklabels=['Not Selected','Selected'])\n",
    "        plt.title('Confusion Matrix :')\n",
    "        plt.ylabel('Actual')\n",
    "        plt.xlabel('Predicted')\n",
    "        return plt\n",
    "\n",
    "    # Method to get the classifier ROC.\n",
    "    def GetModelROC(self):\n",
    "        # Plot the ROC curve for the trained model.\n",
    "        # Calculate the RoC curve\n",
    "        fpr, tpr, thresholds = roc_curve(Y_test_ravel,Y_pred_calib,pos_label=1)   # compute the roc curve.\n",
    "        plt.plot([0, 1], [0, 1], linestyle='--')                                  # plot the 50% probability line.\n",
    "        plt.plot(fpr, tpr, marker='.')                                            # plot the roc curve for the model.\n",
    "        plt.title(\"ROC Curve.\")                                                   # set the title of the plot.\n",
    "        plt.xlabel(\"False Positive Rate\")                                         # set the x label of the plot.\n",
    "        plt.ylabel(\"True Positive Rate\")                                          # set the y label of the plot.\n",
    "        return plt\n",
    "\n",
    "#===== Move this outside of this class ====================================================================================\n",
    "    # Method to get predictions.\n",
    "    def GetPredictionsOnUnseenData(self):\n",
    "        # predict,response from the Logistic Regression model.\n",
    "        global Y_pred_unlabelled\n",
    "        Y_pred_unlabelled = lr_optimal.predict(X_unlabelled_stdzd)\n",
    "        return X_unlabelled_stdzd, Y_pred_unlabelled\n",
    "    \n",
    "    # Method to get calibrated predictons.\n",
    "    def GetCalibratedPredictionsOnUnseenData(self):\n",
    "        # predict class probabilities on the unlabelledset.\n",
    "        global Y_pred_unlabelled_calib\n",
    "        Y_pred_unlabelled_calib = calibratedCCV.predict_proba(X_unlabelled_stdzd)[:, 1] \n",
    "        return X_unlabelled_stdzd, Y_pred_unlabelled_calib\n",
    "#==========================================================================================================================\n",
    "    \n",
    "    # Create all the required App config directories.\n",
    "    def CreateAppDirectories(self):\n",
    "        #======= Extract app config directories from json. ==================\n",
    "        sourceLoc       = self.Source\n",
    "        outputLoc       = self.Output\n",
    "        trainedModelLoc = self.TrainedModel\n",
    "        executionLog    = self.ExecutionLog\n",
    "        archiveLog      = self.Archive\n",
    "        #====================================================================\n",
    "        #====== Check and Create App Config Directories =====================\n",
    "        # Check, if Source directory exists. Else, create new.\n",
    "        if not(os.path.isdir(sourceLoc)):\n",
    "            os.mkdir(sourceLoc)\n",
    "        # Check, if Output directory exists. Else, create new.\n",
    "        if not(os.path.isdir(outputLoc)):\n",
    "            os.mkdir(outputLoc)\n",
    "        # Check, if TrainedModel directory exists. Else, create new.\n",
    "        if not(os.path.isdir(trainedModelLoc)):\n",
    "            os.mkdir(trainedModelLoc)\n",
    "        # Check, if ExecutionLog directory exists. Else, create new.\n",
    "        if not(os.path.isdir(executionLog)):\n",
    "            os.mkdir(executionLog)\n",
    "        # Check, if Archive directory exists. Else, create new.\n",
    "        if not(os.path.isdir(archiveLog)):\n",
    "            os.mkdir(archiveLog)\n",
    "        #====================================================================\n",
    "        #===== Create the ExecutionLog File with a dummy entry ==============\n",
    "        data = {}\n",
    "        data['ExecutionLog'] = []\n",
    "        data['ExecutionLog'].append({\n",
    "            'ID'         :'ClientID',\n",
    "            'ExecutionID':'Global_Unique_Identifier',\n",
    "            'DateTime'   :'Current_Date',\n",
    "            'Class'      :'Python class',\n",
    "            'Method'     :'Python method ',\n",
    "            'StatusType' :'Success|Error',\n",
    "            'Description':'Success|Error',\n",
    "            'User'       :'User Login'\n",
    "\n",
    "        })\n",
    "\n",
    "        with open(executionLog + 'ExecutionLog.txt', 'w+') as outfile:\n",
    "            json.dump(data, outfile)\n",
    "        #====================================================================\n",
    "        \n",
    "    # Write to activity log.\n",
    "    def WriteToActivityLog(self,classApplication,classMethod,statusType,statusDescription=''):\n",
    "        #===== Get the activity details to log ==============================\n",
    "        userlogin   = str(os.getlogin())\n",
    "        currentdt   = str(datetime.now())\n",
    "        guid        = str(uuid.uuid4())\n",
    "        activityLog = self.ExecutionLog\n",
    "        clientID    = self.ClientID\n",
    "        #====================================================================\n",
    "        \n",
    "        #====== Extract the error details to be logged ======================\n",
    "        if statusType != 'Success':\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            f = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            filename = f.f_code.co_filename\n",
    "            linecache.checkcache(filename)\n",
    "            line = linecache.getline(filename, lineno, f.f_globals)\n",
    "            statusDescription = 'Error occurred at line :' + str(lineno) + '| Code:' + str(line.strip()) + '|Error Description :' + str(exc_obj)\n",
    "        #====================================================================\n",
    "        \n",
    "        # Open and read the App Configuration using json.\n",
    "        with open(activityLog + 'ExecutionLog.txt','r+') as json_file:\n",
    "            # Load the App config details.\n",
    "            data = json.load(json_file)\n",
    "\n",
    "        # Append, the activity entry.\n",
    "        data['ExecutionLog'].append({\n",
    "            'ID'         : clientID,\n",
    "            'ExecutionID': guid,\n",
    "            'DateTime'   : currentdt,\n",
    "            'Class'      : classApplication,\n",
    "            'Method'     : classMethod,\n",
    "            'StatusType' : statusType,\n",
    "            'Description': statusDescription,\n",
    "            'User'       : userlogin\n",
    "\n",
    "        })\n",
    "\n",
    "        # Write the activity log to file.\n",
    "        with open(activityLog + 'ExecutionLog.txt', 'w+') as outfile:\n",
    "            json.dump(data, outfile)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6002\n",
      "2001\n"
     ]
    }
   ],
   "source": [
    "total_rowCount = 10003\n",
    "print(round(0.6*total_rowCount))\n",
    "print(round(0.2*total_rowCount))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
